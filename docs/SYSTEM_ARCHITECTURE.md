# システム構成 - Video AITuber

## 概要

Video AITuberは、AIとのチャットをリアルタイムで配信するためのWebアプリケーションです。視聴者からのコメントをAIが読み上げ、アバター動画として配信することで、インタラクティブな配信体験を実現します。

本システムは以下の4つの主要コンポーネントで構成されています。

1. **Movie Tuber（本アプリ）** - フロントエンドUI と APIを提供するNext.jsアプリケーション
2. **Mastra ワークフロー** - LLMを活用したAI応答生成エンジン
3. **動画生成・供給サーバー** - 音声合成とアバターアニメーションを統合した動画生成・供給システム

配信コメントを取得する場合は、別途わんコメ（OneComme）を使用します。

---

## 各コンポーネントの役割

### Video AITuber（本アプリ）

Video AITuberは、システム全体のハブとなるNext.jsアプリケーションです。フロントエンドでは、生成されたアバター動画をリアルタイムで再生し、チャット履歴を表示します。バックエンドでは、Mastraワークフローや動画生成・供給サーバーとの通信を仲介するAPIを提供します。

主な機能として、ユーザーや配信視聴者からのコメント受付、AIへの問い合わせ、動画生成リクエストの発行、生成された動画のストリーミング再生があります。また、事前に用意した台本を直接送信する機能も備えており、LLMを介さずに特定のセリフを喋らせることができます。

動画再生にはダブルバッファリング方式を採用しており、2つのvideoエレメントを交互に使用することで、動画切り替え時の途切れを防いでいます。待機中はループ動画を再生し、AIの応答動画が生成されると自動的に切り替わります。

### Mastra ワークフロー

MastraワークフローはLLMを活用したAI応答生成を担当する独立したサービスです。Movie Tuberから受け取ったコメントを解析し、適切な応答テキストと感情パラメータを生成して返却します。

ワークフロー内では以下の処理が行われます。まず、受け取ったコメントが応答すべきものかどうかを判定します（`shouldRespond`フラグ）。応答する場合は、LLM APIを呼び出して自然な応答テキストを生成します。同時に、応答に適した感情（neutral、happy、thinkingなど）を判定し、音声合成時の抑揚に反映させます。また、ユーザー名の読み仮名も生成し、音声合成で正しく読み上げられるようにします。

このサービスを独立させることで、LLMのプロンプトやワークフローの変更がMovie Tuber本体に影響を与えないアーキテクチャになっています。

### 動画生成・供給サーバー

動画生成・供給サーバーは、テキストと感情パラメータを受け取り、音声付きアバター動画を生成するサービスです。内部ではVOICEVOX（音声合成エンジン）とAnimation Streamer（アバターアニメーション生成）を連携させています。

リクエストを受け取ると、まずVOICEVOXでテキストから音声を合成します。次に、その音声の長さと感情パラメータに基づいてアバターのアニメーションを生成します。最後に、音声とアニメーションを合成してMP4動画ファイルとして出力します。

応答はNDJSON（Newline Delimited JSON）形式でストリーミング返却されるため、複数のリクエストを送った場合でも、生成が完了したものから順次受け取ることができます。これにより、配信中の応答遅延を最小限に抑えています。

対応するアクションとして、`speak`（音声付き発話動画）、`loop`（待機ループ動画）、`idle`（無音待機動画）、`start`/`end`（配信開始・終了用動画）などがあります。

---

## データの流れ

### 通常のチャット処理

ユーザーがチャット入力欄からメッセージを送信すると、Movie Tuberの`/api/chat`エンドポイントが受け取ります。このAPIはMastraワークフローの`/api/workflows/aituberWorkflow/start-async`を呼び出し、AIの応答を取得します。

Mastraからの応答には、応答テキスト、感情、応答要否フラグなどが含まれます。応答する場合は、続けて動画生成サーバーに`speak`アクションのリクエストを送信します。動画生成サーバーは音声合成とアニメーション生成を行い、完成した動画のパスを返却します。

フロントエンドは定期的に（1秒間隔で）コールバックAPIをポーリングし、新しい動画が生成されていれば取得して再生します。

### 配信コメント連携

わんコメを使用する場合、配信視聴者のコメントをOneSDK経由で受信できます。`#`で始まるコメントのみをAIへの問いかけとして処理し、通常のチャット処理と同じフローで動画生成まで行います。

### 台本送信

台本パネルから事前定義されたセリフを選択して送信すると、`/api/script-send`エンドポイントが処理します。このフローではMastraワークフローを経由せず、直接動画生成サーバーにリクエストを送信します。これにより、LLMの判断を介さずに確実に特定のセリフを喋らせることができます。

---

## 環境変数

```env
# 動画生成サーバーのエンドポイント
VIDEO_GENERATION_API_URL=http://localhost:4000/api/generate

# Mastra ワークフローのベースURL
AITUBER_WORKFLOW_URL=http://localhost:4111
```

---

## ポート一覧

| サービス | ポート | 説明 |
|---------|--------|------|
| Movie Tuber | 3000 | メインアプリケーション（Next.js） |
| 動画生成サーバー | 4000 | 音声合成・アバター動画生成 |
| Mastra | 4111 | LLMワークフローエンジン |
| VOICEVOX | 50021 | 音声合成エンジン（デフォルト） |

---

## 起動順序

システムを起動する際は、依存関係を考慮して以下の順序で起動することを推奨します。

1. **VOICEVOX** - 動画生成サーバーが音声合成に使用するため、最初に起動します
2. **動画生成サーバー** - VOICEVOXの起動後に起動します
3. **Mastra** - LLMワークフローエンジンを起動します
4. **Movie Tuber** - 最後にメインアプリケーションを起動します

Movie Tuberは他のサービスへの接続に失敗しても起動自体は可能ですが、該当機能は使用できません。

---

## 技術スタック

| 領域 | 採用技術 |
|------|----------|
| フレームワーク | Next.js 16（App Router） |
| フロントエンド | React 19、Tailwind CSS 4 |
| 言語 | TypeScript（strict mode） |
| API | Next.js API Routes |
| LLM連携 | Mastra ワークフロー経由でHTTP通信 |
| 動画生成 | 外部API（NDJSON形式ストリーミング） |
| 音声合成 | VOICEVOX |
| 動画再生 | HTML5 Video（ダブルバッファリング） |
